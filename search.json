{
  "articles": [
    {
      "path": "about.html",
      "title": "About me",
      "description": "Some additional details about the blog",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas' Research Page\n    \n    \n      \n  Home\n\n\n  Publications\n\n\n  Blog\n\n\n  Calendar\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\nAbout me\n\n\n\n\nI’m a postdoc research working with histopathology image analysis for\ncancer treatment with genetic programming. I was a PhD student at the\nUniversity of Tsukuba (2020-2023). I graduated in Computer Science\n(2016) at the University of Brasilia, Brazil, and I got my Master Degree\nat the University of Tsukuba, Japan (2020).\nI am conducting research since I was an undergraduate student, in\nBrazil at the University of Brasilia. During that time, I was awarded\nwith two research scholarships. During my undergraduate period I had the\nchance to pursuit a sandwich program financed by the Brazilian\ngovernment - Science without Borders - to conduct research in Japan for\na year, at the University of Tsukuba. After graduating, I started a\nmaster course also at University of Tsukuba, with the MEXT scholarship.\nThen, I was granted another MEXT scholarship, to continue my studies in\nJapan, but as a PhD student.\n#### Scholarships\n1. Awarded PhD scholarship by - MEXT - 文部科学省奨学金, 2020.04\nuntil 2023.03 2. Awarded masters scholarship by - MEXT -\n文部科学省奨学金, 2018.04 until 2020.03 3. Awarded research scholarship\nby - MEXT - 文部科学省奨学金, 2017.09 until 2018.03 4. Awarded research\nscholarship by CNPq – National Council for Scientific and Technological\nDevelopment, 2015.08 until 2016.07. 5. Awarded research scholarship by\nCAPES - Coordination for the Improvement of Higher Education Personnel,\n2014.08 until 2015.08. 6. Awarded research scholarship by CNPq -\nNational Council for Scientific and Technological Development, 2014.08\nuntil 2015.07.\n\nResearch interests\nMy research interests are Evolutionary Computation, Multiobjective\nOptimization and Alife.\n\n\nCo-authorship Network\nResearch collaboration/network:\nMarcelo Ladeira and Felipe Vaz\n(University of Brasilia).\n\nLana Sinapayen, (Sony Computer Science Labs’ new\nKyoto Lab).\nGabriela Ochoa, (University of Stirling).\nFelipe Campelo, (Aston University).\nRicardo Torres (University of Norwegian University\nof Science and Technology).\n\n\n\n\n\n\n\n",
      "last_modified": "2024-11-18T12:35:12+01:00"
    },
    {
      "path": "blog.html",
      "title": "My blog",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas\n    \n    \n      \n  Home\n\n\n  Publications\n\n\n  Blog\n\n\n  Calendar\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\nMy blog\n\n\n\n\n\nFirst post\nHello, all. I’m happy to introduce my research blog. This is where I\nwill write about my research projects and other related stuff that I\nfind interesting.\n\nLiving abroad experiences\nHi, again. This is my second post, and, wow, after a really long\ntime. This time, I’m moving a little away from research topics and I\nwill discuss a little my experiences while living abroad.\n\nTODO\n\n\n\nVisualizations\nHi, again. This is my first blog post. The idea here is to show a\nlittle of my research is a different way to the traditional papers that\nwe read. I hope you can enjoy reading it as I did when I wrote this.\n\nPersonal motivation\nRecently I started to be interested in visualising evolutionary\nalgorithms (EAs). Here, I will summarise some fascinating works that\nhelped me create an interest in the field of study.\n\nWhat are these visualisation tools?\nThe main idea of visualising EAs is to show efficient ways of\ncommunicating the behaviour of such algorithms. What is remarkable about\nlooking at the images is that we can look at them,\nwhich feels a little less abstract. I’m sure you saw some of these\ntools, and one of the most common is the fitness landscapes.\nIn a population-based algorithm:\n\nIn a gradient descent algorithm (commonly used in Neural Networks and\nother ML algorithms):\n\nIn case this is your first time hearing about the fitness landscape,\nlet me give a summary of what they are:\nFitness Landscapes are used to visualise the relationship between\nsolutions and their fitness values.\nSimilar solutions are closer to each other, different solutions are\nfar from each other. The set of all possible solutions, their degree of\nsimilarity, and corresponding fitness values is called a fitness\nlandscape.\nThe higher the fitness, the higher is the landscape.\nAre you interested? Take a look at this Wikipedia page: https://en.wikipedia.org/wiki/Evolutionary_landscape.\nOr watch this YouTube video: https://www.youtube.com/watch?v=4pdiAneMMhU\n\n\n\nFrom 1 to many\nThat’s super, isn’t it? These methods were developed for\nsingleobjective algorithms, and we don’t have yet many tools to\nvisualize multiobjective EAs. Having tools like this can help us to\ncreate new and (hopefully) better algorithms. That is because we can see\nhow the process changes over time, and then we an study the strengths\nand weaknesses of algorithms. And by knowing these strengths and\nweaknesses we can improve existing algorithms or even create new and\nbetter EAs.\n\n(Disclaimer: Is new always better? I love this meme, so I couldn’t\nresist adding it here, but new doesn’t mean better. Btw, what does it\nmean to be better?)\n\n\nMethods that I think are worth mentioning\nHere I will discuss visualisation methods for the multiobjective\ndomain that I have already successfully used.\n\nAnytime hypervolume performance\nAnalysing algorithms using the final approximation provides limited\ninformation related to these algorithms’ performance since these EAS\nshould return a suitable set of solutions at any time during the search\n[1,2,3,4]. That is, looking at the whole process, not only at the end,\nprovides more insightful information.\n\nThis image shows the Anytime HV (higher is better, shaded areas\nindicate the standard deviation) on UF10. The performance of MOEA/D-PS\nis shown as the red circles, MOEA/D with population size 500 is shown as\nthe green triangles, and MOEA/D with population size equals 50 is shown\nas the blue squares, on UF10. The anytime performance of MOEA/D-PS is\nsimilar to the anytime performance of MOEA/D with a small population. We\ncan see that the three variants have almost the same performance at the\nend of the search. This image and text are from [5].\nSee? The 3 algorithms have the same final performance, but how they\ngot there was different.\n\n\n\nEmpirical Attainment Performance\nThe empirical attainment function (EAF) allows the examination of the\nsolution many sets of different runs of an algorithm. It can illustrate\nwhere and by how much the outcomes of the two algorithms differ in the\nobjective space [6]. The EAF is based on the attainment surface and\nresents the probability that an arbitrary objective region in the\nobjective space is attained (dominated or equal) by an algorithm, and\nprobability can be estimated using data collected from several\nindependent runs such algorithm. The attained surface separates the\nobjective space into two regions: (1) where the objective space is\ndominated (attained) by solutions of many sets and (2) where the\nobjective space is not dominated by those solutions [7,8]. For example,\nthe median attainment surface shows regions dominated by at least half\nof the runs [6].\n\nThe shades of red show the amount of the differences of the\nprobabilistic distribution of the outcomes obtained by the algorithms:\nshades closer to red indicate higher differences between the probability\ndistributions, shades closer to orange indicate little difference and\nshades closer to white indicate no difference. Again, this image and\ntext are from [5].\nSee? The algorithm on the left performs better at central regions of\nthe objective space. The algorithm on the right performs better at the\nside regions. So, if you prefer more balanced solutions, choose the\nalgorithm from the left, if you prefer extreme solutions, then the one\nof the right is the right one.\n\n\n\nSearch Trajectory Networks\nSearch Trajectories Networks (STNs) of multiobjective evolutionary\nalgorithms is a new tool that I, together with Gabriela Ochoa and Claus\nAranha, have developed and just been accepted for publication at this\nyear’s EvoStar conference.\n\nPS: I’ve been nominated as an “Outstanding Student” for this\nwork!\n\n(Disclaimer: Another meme that I love and that I couldn’t resist\nadding here. 99!)\nIn our work, we extend the search trajectory networks models (STNs)\nproposed for single objective EAs. The main difference between STNs in\nthe singleobjective and the multiobjective domains is that we use the\nidea of decomposition. The decomposition transforms a multiobjective\nproblem into several single-objective problems. So, now we can create\nSTNs for the multiobjective domain!\nTo see how effective this STN are, we generated STNs models for\nMOEA/D and NSGA-II. First, I’m showing the STN of the MOEA/D on the UF10\nproblem:\n\nFirst, I’m showing the STN of the NSGA-II on the same problem:\n\nSee how different they are? For example, the first STN, of MOEA/D, is\nmuch more dense that the STN of NSGA-II. Not only that, but the MOEA/D\nSTN showed more nodes (coloured circles) indicating that the algorithm\nis exploring more the search space, while the NSGA-II STN keeps going\nback to the end node (the size of the black triangle indicates that this\nnode is reached multiple times).\nAnalysing the STNs showed us that we can effectively apply them to\ndifferentiate multiobjective EAs visually and quantitatively. This is\ngreat because we can add together this information to the traditional\ncomparing metrics, such as HV and IGD.\n\nAlso, they are beautiful! Or is it just me?\nFor more information, see this Twitter thread.\nhttps://twitter.com/yurilavinas/status/1499681390019092487\nOr read the preprint version: https://t.co/1GAkPy0R9K.\nWell, this is it for today. I hope you found this helpful. See you\nnext time!\n\n\nReferences\n[1] Zilberstein, S. (1996). Using anytime algorithms in intelligent\nsystems. AI magazine, 17(3), 73-73.\n[2] Radulescu, A., López-Ibánez, M., & Stützle, T. (2013, March).\nAutomatically improving the anytime behaviour of multiobjective\nevolutionary algorithms. In International Conference on Evolutionary\nMulti-Criterion Optimization (pp. 825-840). Springer, Berlin,\nHeidelberg.\n[3] Dubois-Lacoste, J., López-Ibáñez, M., & Stützle, T. (2015).\nAnytime Pareto local search. European journal of operational research,\n243(2), 369-385.\n[4] Tanabe, R., Ishibuchi, H., & Oyama, A. (2017). Benchmarking\nmulti-and many-objective evolutionary algorithms under two optimisation\nscenarios. IEEE Access, 5, 19597-19619.\n[5] Lavinas, Y., Aranha, C., & Ladeira, M. (2022). Faster\nConvergence in Multiobjective Optimisation Algorithms Based on\nDecomposition. Evol Comput 2022; DOI: https://doi.org/10.1162/evco_a_00306.\n[6] López-Ibáñez, M., Paquete, L., & Stützle, T. (2010).\nExploratory analysis of stochastic local search algorithms in\nbiobjective optimisation. In Experimental methods for the analysis of\noptimisation algorithms (pp. 209-222). Springer, Berlin, Heidelberg.\n[7] Fonseca, C. M., & Fleming, P. J. (1996, September). On the\nperformance assessment and comparison of stochastic multiobjective\noptimisers. In International Conference on Parallel Problem Solving from\nNature (pp. 584-593). Springer, Berlin, Heidelberg.\n[8] Fonseca, V. G. D., Fonseca, C. M., & Hall, A. O. (2001,\nMarch). Inferential performance assessment of stochastic optimisers and\nthe attainment function. In International Conference on Evolutionary\nMulti-Criterion Optimization (pp. 213-225). Springer, Berlin,\nHeidelberg.\n[9] Lavinas, Y., Aranha, C., & Ochoa, G. (2022). Search\nTrajectories Networks of Multiobjective Evolutionary Algorithms. arXiv\npreprint arXiv:2201.11726.\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2024-11-18T12:48:04+01:00"
    },
    {
      "path": "calendar.html",
      "title": "Calendar",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas\n    \n    \n      \n  Home\n\n\n  Publications\n\n\n  Blog\n\n\n  Calendar\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\nCalendar\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2024-11-18T12:57:41+01:00"
    },
    {
      "path": "index.html",
      "title": "Hi, My name is Yuri Lavinas.",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas\n    \n    \n      \n  Home\n\n\n  Publications\n\n\n  Blog\n\n\n  Calendar\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\nHi, My name is Yuri Lavinas.\n\n\n\n\n\nI’m an associate professor at the University of Toulouse 1 Capitole, France, at\nthe Institut\nde Recherche en Informatique de Toulouse (IRIT) and I’m part of the\nREVA\nteam. I did a postdoc research working with histopathology image\nanalysis for cancer treatment with Genetic Programming in the IRIT@CRCT group. I got\nmy PhD degree from the University of Tsukuba, Japan. Originally, I’m\nfrom Brazil, where I did my undergraduate course, at the University of\nBrasilia.\nMy research interests are related to Computational Intelligence, such\nas Evolutionary Computation and Artificial Life, with a greater focus on\nmulti-objective optimization, fitness landscape and Genetic Programming.\nOverall, I’m interested in programs that can adapt themselves, in\napplications of Evolutionary Computation (black box optimization,\nmulti-agent systems, games), as well as more speculative use of these\nComputational Intelligence for Artificial Life ( such as the evolution\nof virtual creatures and the worlds where the live).\n\nGeneral Information\nCheck my Publication\nList.\nI was part of the Autoadaptation\nin Multi-Objective Optimization group, under Prof. Claus\nAranha supervision.\n\n\nFollow me\nTalk to me on Twitter.\nFind my papers in my Google\nScholar profile or in my ResearchGate\nprofile.\nMost of my projects are on Github.\nSend me an e-mail. You can\nalso find my contact information at the top of the page.\n\n\nScholarships\nAwarded PhD scholarship by - MEXT - 文部科学省奨学金, 2020.04 until\n2023.03\nAwarded masters scholarship by - MEXT - 文部科学省奨学金, 2018.04\nuntil 2020.03\nAwarded research scholarship by - MEXT - 文部科学省奨学金, 2017.09\nuntil 2018.03\nAwarded research scholarship by CNPq – National Council for\nScientific and Technological Development, 2015.08 until 2016.07.\nAwarded research scholarship by CAPES - Coordination for the\nImprovement of Higher Education Personnel, 2014.08 until 2015.08.\nAwarded research scholarship by CNPq - National Council for\nScientific and Technological Development, 2014.08 until 2015.07.\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2024-11-18T12:44:54+01:00"
    },
    {
      "path": "publications.html",
      "title": "Publications",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas\n    \n    \n      \n  Home\n\n\n  Publications\n\n\n  Blog\n\n\n  Calendar\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\nPublications\n\n\n\n\nSend me an e-mail if you\nhave any questions about these publications.\nPublications are listed in chronological order, and the horizontal\nline separates peer-reviewed publications.\n\n2024\nYuri Lavinas, Nathaniel Haut, William Punch, Wolfgang\nBanzhaf, Sylvain Cussat-Blanc. Dynamically Sampling biomedical\nImages For Genetic Programming, In Proceedings of the Companion\nConference on Genetic and Evolutionary Computation (GECCO ’24\nCompanion). https://doi.org/10.1145/3638530.3654202 For the\npreprint, send me an email.\n\nYuri Lavinas, Nathaniel Haut, William Punch, Wolfgang\nBanzhaf, Sylvain Cussat-Blanc. Data sampling via Active Learning\nin Cartesian Genetic Programming for Biomedical Data, (CEC), https://doi.org/10.1109/CEC60901.2024.10611879 For the\npreprint, send me an email.\n\nYuri Lavinas, Nathan Haut, William Punch, Wolfgang\nBanzhaf, Sylvain Cussat-Blanc. Adaptive Sampling of Biomedical\nImages with Cartesian Genetic Programming, Parallel Problem\nSolving From Nature (PPSN 2024). https://doi.org/10.1007/978-3-031-70055-2_16 For the\npreprint, send me an email.\n\nCamilo De La Torre, Sylvain Cussat-Blanc, Dennis G Wilson,\nYuri Lavinas On Search Trajectory Networks for Graph\nGenetic Programming. In Proceedings of the Companion Conference\non Genetic and Evolutionary Computation (GECCO ’24 Companion). https://doi.org/10.1145/3638530.3664169 For the\npreprint, send me an email.\nCamilo De La Torre, Yuri Lavinas, Kévin Cortacero, Hervé\nLuga, Dennis G Wilson, Sylvain Cussat-Blanc, Multi-Modal\nAdaptive Graph Evolution for Program Synthesis, Parallel\nProblem Solving From Nature (PPSN 2024). https://doi.org/10.1007/978-3-031-70055-2_19 For the\npreprint, send me an email.\n\nYuri Lavinas, Marcelo Ladeira, Gabriela Ochoa, Claus\nAranha. Multiobjective Evolutionary Component Effect on\nAlgorithm behavior, Multiobjective Evolutionary Component\nEffect on Algorithm behavior. ACM Transactions on Evolutionary Learning\nand Optimization. https://dl.acm.org/doi/10.1145/3612933 Preprint.\n\n\n2023\nGabriela Ochoa, Arnaud Liefooghe, Yuri Lavinas, Claus\nAranha. Decision/Objective Space Trajectory Networks for\nMulti-objective Combinatorial Optimisation, Evolutionary\nComputation in Combinatorial Optimization. EvoCOP 2023. https://doi.org/10.1007/978-3-031-30035-6_14 Preprint.\nPaul Mitchel, Gabriela Ochoa, Yuri Lavinas, Romain\nChassagne. Local Optima Networks for Seismic History Matching\nProblems, EvoApplications 2023. https://doi.org/10.1007/978-3-031-30229-9_6 Preprint.\nAlexandre Mascarenhas, Yuri Lavinas, Claus Aranha.\nAbCD: A Component-wise Adjustable Framework for Dynamic\nOptimization Problems, In Proceedings of the Companion\nConference on Genetic and Evolutionary Computation (GECCO ’23\nCompanion). https://doi.org/10.1145/3583133.3590655 Extended\nversion.\nYuri Lavinas, Kevin Cortacero, Sylvain Cussat-Blanc.\nEvolving Graphs with Cartesian Genetic Programming with Lexicase\nSelection, In Proceedings of the Companion Conference on\nGenetic and Evolutionary Computation (GECCO ’23 Companion). https://doi.org/10.1145/3583133.3596402 Preprint.\n\n\n2022\nYuri Lavinas, Marcelo Ladeira, Claus Aranha.\nFaster Convergence in Multi-Objective Optimization Algorithms\nBased on Decomposition Evolutionary Computation, 2022,\nEvolutionary Computation, doi: https://doi.org/10.1162/evco_a_00306 Preprint.\nYuri Lavinas, Claus Aranha, Gabriela Ochoa.\nSearch Trajectories Networks of Multiobjective Evolutionary\nAlgorithms, 2022 Conference on the Applications of Evolutionary\nComputation (Part of EvoStar), doi: https://doi.org/10.1007/978-3-031-02462-7_15 Preprint.\nThis work was nominated as candidate for the student\nbest paper of EvoStar 2022.\nThis work was nominated as candidate for the best paper\nof EvoStar 2022.\nYuri Lavinas, Marcelo Ladeira, Claus Aranha, Gabriela\nOchoa. Component-wise Analysis of Automatically Designed\nMultiobjective Algorithms on Constrained Problems, 2022 GECCO,\ndoi https://doi.org/10.1145/3512290.3528719 Preprint.\nThis work was nominated as candidate for the best paper\nof the EMO track GECCO 2022.\n\n\n2021\nFelipe Vaz, Yuri Lavinas, Claus Aranha, Marcelo Ladeira.\n“Exploring Constraint Handling Techniques in Real-world Problems\non MOEA/D with Limited Budget of Evaluations”, 2021\nEvolutionary Multi-Criterion Optimization (EMO), doi: https://doi.org/10.1007/978-3-030-72062-9_44 Preprint.\nWatch EMO 2021 presentation\nvideo on YouTube.\nYuri Lavinas, Abe Mitsu Teru, Yuta Kobayashi, and Claus\nAranha. “MOEA/D with Adaptative Number of Weight\nVectors”, In Theory and Practice of Natural Computing,\npp. 134-146, Cham, 2021. Springer International Publishing, doi: https://doi.org/10.1007/978-3-030-90425-8_7. Preprint.\n\n\n2020\nYuri Lavinas, C. Aranha, M. Ladeira and F. Campelo,\n“MOEA/D with Random Partial Update Strategy,” 2020 IEEE\nCongress on Evolutionary Computation (CEC), Glasgow, United Kingdom,\n2020, pp. 1-8, doi: https://doi.org/10.1109/CEC48606.2020.9185527. Preprint.\nWatch CEC 2020 presentation\nvideo on YouTube.\nNicolo Oreste Pinciroli Vago, Yuri Lavinas, Daniele\nRodrigues, Felipe Moura, Sergio Cunha, Claus Aranha, and Ricardo da\nSilva Torres, “INTEGRA: An Open Tool To Support Graph-Based\nChange Pattern Analyses In Simulated Football Matches”, 34th\nInternational ECMS Conference on Modeling and Simulation, 2020.06 DOI:\nhttps://doi.org/10.7148/2020-0228 Link.\nYuri\nLavinas, Claus Aranha, Marcelo Ladeira, Tetsuya Sakurai, “Resource\nAllocation and Population Size in MOEA/D” Symposium of the Japanese\nSociety of Evolutionary Computation (2020.09).\nWatch JSEC 2020 presentation\nvideo on YouTube.\n\n\n2019\nYuri Lavinas, Claus Aranha, Tetsuya Sakurai,\n“Using Diversity as a Priority Function for Resource Allocation\non MOEA/D”, In Genetic and Evolutionary Computation Conference\nCompanion (GECCO ’19 Companion), https://doi.org/10.1145/3319619.3321948, 2019.7 Preprint.\nYuri Lavinas, Claus Aranha, and Marcelo Ladeira.\n“Improving resource allocation in MOEA/D with decision-space\ndiversity metrics”. In Theory and Practice of Natural\nComputing, pp. 134–146, Cham, 2019. Springer International Publishing,\nhttps://www.doi.org/10.1007/978-3-030-34500-6_9,\n2019.12\nYuri\nLavinas, Claus Aranha, Marcelo Ladeira, Tetsuya Sakurai,\n“Resource Allocation in MOEA/D: What is important?”\nSymposium of the Japanese Society of Evolutionary Computation\n(2019.09).\n\n\n2018\nYuri Lavinas, Claus Aranha, Tetsuya Sakurai, Marcelo\nLadeira, “Experimental Analysis of the Tournament Size on\nGenetic Algorithms”, IEEE International Conference on Systems,\nMan and Cybernetics, pp.3647-3653, https://doi.org/10.1109/SMC.2018.00617, 2018.10. Preprint.\nYuri Lavinas, Claus Aranha, Tetsuya Sakurai,\n“Resource Allocation by Diversity” Symposium of the\nJapanese Society of Evolutionary Computation (2018.12)\n\n\n2017\nYuri Lavinas, Claus Aranha, Marcelo Ladeira,\n“Experimental Analysis of the Tournament Size on Evolutionary\nAlgorithms” Symposium of the Japanese Society of Evolutionary\nComputation (2017.12)\n\n\n2016\nYuri Lavinas, Marcelo Ladeira, Claus Aranha,\n“Inducao de Modelo de Risco de Sismos com Tecnicas de Algoritmos\nGeneticos” - 68th Annual Meeting of the Brazilian Science\nSociety (SBC) (2016.7) (Poster, in Portuguese).\n\n\n2014\nClaus Aranha, Yuri Cossich Lavinas, Marcelo Ladeira and\nBogdan Enescu: “Is it possible to generate good Earthquake Risk\nModels using Genetic Algorithms?”, 6th International Conference\non Evolutionary Computation Theory and Applications (ECTA), https://doi.org/10.5220/0005072600490058.\n\n\n\n\n\n\n\n",
      "last_modified": "2024-12-01T12:15:37+01:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas' Research Page\n    \n    \n      \n  Home\n\n\n  Profile\n\n\n  Research\n\n\n  Blog\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\n\n\n\n\n\nyclavinas.github.io\n\n\n\n\n\n\n\n",
      "last_modified": "2024-05-22T09:38:28+02:00"
    },
    {
      "path": "reseach_projects.html",
      "title": "Research Projects",
      "author": [],
      "contents": "\n\n\n\n\n\n\n\n\n  \n    \n      \n        \n        \n        \n      \n      Yuri Lavinas' Research Page\n    \n    \n      \n  Home\n\n\n  Publications\n\n\n  Blog\n\n\n  About me\n\n      \n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n\n  \n    \n     \n  \n\n      \n  \n\n\n\n\n\n\nResearch Projects\n\n\n\n\nMy research interests are Genetic Algorithms, Artificial Intelligence, Evolutionary Computation, and Artificial Life.\nFor more information, check my publication list or send me an e-mail.\n\nSummary of the projects\n\nMOEA/D and Partial Update of the Population\nSummary of the following works:\nYuri Lavinas, C. Aranha, M. Ladeira and F. Campelo, “MOEA/D with Random Partial Update Strategy,” 2020 IEEE Congress on Evolutionary Computation (CEC), Glasgow, United Kingdom, 2020, pp. 1-8, doi: https://doi.org/10.1109/CEC48606.2020.9185527. Preprint.\nWatch CEC 2020 presentation video on YouTube.\nA visual tool that positions the current research in the literature.\nYuri Lavinas, Claus Aranha, Testuya Sakurai, “Using Diversity as a Priority Function for Resource Allocation on MOEA/D”, In Genetic and Evolutionary Computation Conference Companion (GECCO ’19 Companion), https://doi.org/10.1145/3319619.3321948, 2019.7 Preprint.\nA visual tool that positions the current research in the literature.\nYuri Lavinas, Claus Aranha, and Marcelo Ladeira. “Improving resource allocation in MOEA/D with decision-space diversity metrics”. In Theory and Practice of Natural Computing, pp. 134–146, Cham, 2019. Springer International Publishing, https://www.doi.org/10.1007/978-3-030-34500-6_9, 2019.12 Preprint.\nA visual tool that positions the current research in the literature.\nMulti-objective optimization algorithms (MOP solvers) are hard problems, since finding the best solutions for multi-objective problems can be very computationally expensive. One common approach that MOP solvers use when trying to solve MOP is to decompose the MOP into many subproblems. In general, those MOP solvers give the same computational effort to them all. This has some drawbacks:\nSome subproblems are harder than others; thus, the MOP solver requires more computational effort to find better solutions;\nThe MOP solvers might waste computational effort improving solutions that require much effort to improve.\nTo minimize the effect of these drawbacks, I focus my research on\nminimizing computational effort on multi-objective optimization algorithms and\nimproving the performance of multi-objective optimization algorithms (MOP solvers) by making them adapt to the characteristics of the problems.\n\nFig. 1: Hypevolume values (Higher is better) of MOEA/D with different resource allocation techniques. Limiting the computational effort to 10% of the standard amount each iteration improves MOEA/D. Results are superior than those from MOEA/D (100%) and MOEA/D with R.I. (the most used metric for resource allocation.)\n\nI studied methods to guide the distribution of computational effort adaptatively in based-on information on the features of the MOP, using priority functions. I proposed different priority functions that allow MOEA/D to explore better the search space; thus, MOEA/D can find different and better solutions more efficiently. I observed that MOEA/D improves its performance when only a subset of the solution set is updated on each iteration.\n\nFig. 2: Resource allocation on the UF7 function. The horizontal axis indicates the subproblems, while the vertical axis indicates the number of updates accumulated over the optimization. Higher values on the vertical axis indicate higher priority for that subproblem. The horizontal red line indicates the default number of updates (with no Resource Allocation).\n\nI am studying in details what are the reasons for the improvement in performance in MOEA/D with priority functions to specify a theoretical justification for the efficacy of MOEA/D with priority functions, careful examining MOEA/D relates to important issues, such as the ability to find solutions closer to the optima and the ability to find different near-optimal solutions. To improve our understanding of MOEA/D I am studying which components interact well with priority functions to provide a recommendation of MOEA/D component configuration for the community. This will be achieved by a comprehensive and systematic anytime analysis conducted on the combined effect of components, MOEA/D, and priority functions.\n\nFig. 3: Anytime HV (higher is better) performance of MOEA/D-PS for different values of ps on DTLZ6. MOEA/D-PS defines an expected amount of solutions updated at each iteration, regulated by a control parameter, ps. Using 10% of the standard computational effort (number of functions evaluations) is better than using the standard computational effort (100%).\n\nFuture works also include finding ways to improve the performance of MOEA/D on simulated real-world problems using MOEA/D variants that use resource allocation since they show promising results in MOP without constraints.\n\n\nExploring Constraint Handling Techniques in Real-world Problems\nSummary of following work:\nFelipe Vaz, Yuri Lavinas, Claus Aranha, Marcelo Ladeira. “Exploring Constraint Handling Techniques in Real-world Problems on MOEA/D with Limited Budget of Evaluations”, To appear at EMO 2021. Preprint.\nWatch EMO 2021 presentation video on YouTube.\nA visual tool that positions the current research in the literature.\nThis work aims to investigate and explore the effects and behavior of constraint handling techniques (CHTs) in MOEA/D when solving real-world MOPs with a limited budget of evaluations. For that, we compare real-world analytic MOPs and two simulated MOPs: (1) the problem of selecting landing sites for a lunar exploration robot; and (2) the problem of optimization of car designs. To further enhance the performance of MOEA/D, we propose an efficient CHT that works well with problems that require an exploration of the unfeasible search space.\n\nFig. 1: Anytime mean hypervolume (HV, higher is better) performance of the different CHT in MOEA/D in the MAZDA car problem. Our newly proposed Constraint Handling Technique, the Three Stage CHT, achieves the best values at the end of the search execution.\n\n\nFig. 2: Anytime mean HV (higher is better) performance of the different CHT in MOEA/D in the moon landing problem. The Three Stage CHT has the competitive performance with most of the other CHT, but is overcomed by the Fast growth Dynamic CHT.\n\nIt is noticeable that using CHTs can be responsible for increments in hypervolume values compared to traditional MOEA/D without penalty. It comes with no surprise that while a CHT may be a reasonable choice for a given multi-objective problem (MOPs), this CHT might still perform poorly in other MOPs, with different characteristics.\n\n\nHuman-Computer Collaboration for the Generation of Soccer Strategies\nSummary of following work:\nNicolo Oreste Pinciroli Vago, Yuri Lavinas, Daniele Rodrigues, Felipe Moura, Sergio Cunha, Claus Aranha, and Ricardo da Silva Torres, “INTEGRA: An Open Tool To Support Graph-Based Change Pattern Analyses In Simulated Football Matches”, 34th International ECMS Conference on Modeling and Simulation, 2020.06 DOI: https://doi.org/10.7148/2020-0228 Link.\nA visual tool that positions the current research in the literature.\nThis project proposes the simulation of football players and games, using Multi-AgentSystem technologies and based on the graph models developed. The Multi-Agent Simulation will allow the visualization, validation, and exploration of the football player models, leading to a greater understanding of the relationship between the models and the real-world data and extrapolations of many different scenarios using the rules derived from the models.\n\nFig. 1: Example of a full simulated game on the Google Research Football environment, a open-source soccer simulator, from GRF Game Server.\n\nThe resulting simulator will also be used to help coaches and educators. The simulator will assist them with planning and decision making by giving these professionals the tools to simulate fictional scenarios in the simulation and observe how these scenarios play out. The simulator will also allow these professionals to obtain easily understandable outputs from the model in the form of video games between simulated agents, leading to an interactive process of trial, error, and discovery.\n\nFig. 2: Example of real output of a game where one player is controlled by an Artificial NeuralNetwork using the Proximal Policy Optimization.\n\nPreliminary results are very promising and achieved results are expected to be of interest for both simulator developers and those interested in improving team and player performance based on simulated data.\n\nFig. 3: Spread time series for teams A and B in a game style where one player is controlled by an Artificial Neural Network using the Proximal Policy Optimization.\n\nOngoing work refers to deepening our understanding regarding the different simulation variations, aiming to address the following research questions:\nHow to “calibrate” simulated matches in order to properly handle sampling issues and interruptions?\nHow do different simulations differ from each other?\nWhich kinds of simulated matches are more similar to professional matches?\nWhich kinds of simulated matches better encode intrinsic tactical relationships (coordination) between teams?\n\n\n\n\n\n\n\n\n",
      "last_modified": "2024-05-22T09:38:28+02:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
